{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Основы метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход подаются 2 массива $y_{real}$ - реальные значения бинарных классов и $y_{pred}$ - предсказанные значения бинарных классов. Вам необходимо посчитать, не используя стандартные функции, метрики: \n",
    "* $accuracy$\n",
    "* $precision$\n",
    "* $recall$\n",
    "* $F_1$\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.625, 0.75, 0.6, 0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.625, 0.75, 0.6, 0.6666666666666665)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def main_metrics(y_real, y_pred) -> (float, float, float, float):\n",
    "    tp, fn, fp, tn = 0, 0, 0, 0\n",
    "    for i in range(y_real.shape[0]):\n",
    "        if y_pred[i] == 1:\n",
    "            if y_real[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp +=1\n",
    "        else:\n",
    "            if y_real[i] == 1:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "print(main_metrics(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Основы метрик регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу регрессии. На вход подаются 2 массива $y_{real}$ - реальные значения функции и $y_{pred}$ - предсказанные значения функции. Вам необходимо посчитать, не используя стандартные функции, метрики: \n",
    "* $R^2score$\n",
    "* $MAE$ - `mean_absolute_error`\n",
    "* $MSE$ - `mean_squared_error`\n",
    "* $MSLE$ - `mean_squared_log_error`\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "Формулы для метрик - ищите в интернете, это часть задания. Можете сверяться с реальными метриками в `sklearn.metrics`.\n",
    "\n",
    "Все числа в тестах больше 0, поэтому $MSLE$ будет считаться корректно\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.797297, 0.6, 0.6, 0.037856\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7972972972972974, 0.6, 0.6, 0.03785687634230184)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "def reg_metrics(y_real, y_pred) -> (float, float, float, float):\n",
    "    def my_mae(y_real, y_pred):\n",
    "        n = y_real.shape[0]\n",
    "        metric = 0\n",
    "        for i in range(n):\n",
    "            metric += abs(y_real[i] - y_pred[i])\n",
    "        return metric / n\n",
    "\n",
    "    def my_mse(y_real, y_pred):\n",
    "        n = y_real.shape[0]\n",
    "        metric = 0\n",
    "        for i in range(n):\n",
    "            metric += pow(y_real[i] - y_pred[i], 2)\n",
    "        return metric / n\n",
    "\n",
    "    def my_msle(y_real, y_pred):\n",
    "        n = y_real.shape[0]\n",
    "        metric = 0\n",
    "        for i in range(n):\n",
    "            metric += pow(log(y_real[i] + 1) - log(y_pred[i] + 1), 2)\n",
    "        return metric / n\n",
    "\n",
    "    def my_r2(y_real, y_pred):\n",
    "        n = y_real.shape[0]\n",
    "        res = 0\n",
    "        tot = 0\n",
    "        for i in range(n):\n",
    "            res += pow(y_real[i] - y_pred[i], 2)\n",
    "            tot += pow(y_real[i] - np.mean(y_real), 2)\n",
    "        return 1 - res/tot\n",
    "    \n",
    "    mae = my_mae(y_real, y_pred)\n",
    "    mse = my_mse(y_real, y_pred)\n",
    "    msle = my_msle(y_real, y_pred)\n",
    "    r2 = my_r2(y_real, y_pred)\n",
    "    return r2, mae, mse, msle\n",
    "\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "print(reg_metrics(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) LogLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте свой LogLoss метрику.\n",
    "\n",
    "В результат $y_{real}$ - передаются значения бинарных классов. В $y_{prob}$ - передаются вероятности $P(y_{pred}=1)$. Чтобы обработать краевые случаи в $y_{prob}$: \n",
    "* $0$ нужно заменить на `eps`\n",
    "* $1$ нужно заменить на ($1$ - `eps`).\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([  1, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6,   0])\n",
    "```\n",
    "#### Output:\n",
    "``` python\n",
    "    0.325921\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3259215791685959\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "def logloss(y_real: np.array, y_prob: np.array, eps=1e-15) -> float:\n",
    "    y_prob[y_prob == 1] = 1 - eps\n",
    "    y_prob[y_prob == 0] = eps\n",
    "    metric = 0\n",
    "    n = y_real.shape[0]\n",
    "    for i in range(y_real.shape[0]):\n",
    "        metric += (y_real[i] * log(y_prob[i])) + (((1 - y_real[i]) * log(1 - y_prob[i])))\n",
    "    return - metric / n\n",
    "\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_pred = np.array([  1, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6,   0])\n",
    "print(logloss(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Нахождение Roc-curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход даны $y_{real}$ и массив вероятностей $P(y_{pred}=1)$ необходимо реализовать функцию `roc-curve`, которая вернет 2 массива различных значений fpr и tpr, для дальнейшего построения Roc кривой.\n",
    "\n",
    "Можно считать, что все вероятности ограничены $decimal=2$ (у каждого числа не более 2-х знаков после запятой)\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0.,  0.4, 0.6, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "### Sample 2\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0., 0.25, 0.5, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "\n",
    "или \n",
    "\n",
    "array([0.,  0., 0.5, 1. ]), #fpr\n",
    "array([0., 0.5,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "Обратите внимание на 2 пример: roc кривая, которая задается ими - одинаковая. Точка, которая уходит, находится на прямой между двумя соседними, в целом такие точки можно убирать, но будут приниматься оба варианта. Функция `sklearn.metrics.roc_curve` возвращает второй вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp  0  fp  0  tn  5  fn 4\n",
      "tp  2  fp  0  tn  5  fn 2\n",
      "tp  3  fp  2  tn  3  fn 1\n",
      "tp  4  fp  3  tn  2  fn 0\n",
      "tp  4  fp  5  tn  0  fn 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 0.4, 0.6, 1.0], [0.0, 0.5, 0.75, 1.0, 1.0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def roc(y_real: np.array, y_prob: np.array) -> (np.array, np.array):\n",
    "    thresholds = list(set(y_prob))\n",
    "    thresholds.append(1)\n",
    "    thresholds.sort(reverse=True)\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    for threshold in thresholds:\n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        for i in range(len(y_real)):\n",
    "            value = y_real[i]\n",
    "            prob = y_prob[i]\n",
    "            if prob >= threshold:\n",
    "                if value == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                if value == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "        fpr = fp / (fp + tn)\n",
    "        tpr = tp / (tp + fn)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    return fprs, tprs\n",
    "\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "roc(y_real, y_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход падаются [данные](https://yadi.sk/d/6pUM_Ko-RtqiZg) и $k$ - число фолдов в кросс-валидации. Верните значения кросс-валидации по $k$ фолдам алгоритма `LogisticRegression` с метрикой `neg_log_loss`. \n",
    "\n",
    "В итоге должны получиться значения не ниже $-1$.\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "X = pd.read_csv('resources/train.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('resources/train.csv')['y']\n",
    "k = 3\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([-0.45456358, -0.41684932, -0.49260998])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75233645 0.79439252 0.78301887]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import pandas as pd\n",
    "\n",
    "def crossvalidate(X, y, k):\n",
    "    retrun cross_val_score(LR(), X, y, cv=k)\n",
    "\n",
    "X = pd.read_csv('resources/train.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('resources/train.csv')['y']\n",
    "k = 3\n",
    "crossvalidate(X, Y, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) и верните обученный grid_search. \n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные по [ссылке](https://yadi.sk/d/6pUM_Ko-RtqiZg)\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00114317, 0.00173845, 0.00125279, 0.00158863, 0.00068178,\n",
       "        0.00090456, 0.00076699, 0.00100813, 0.00071802, 0.00077796,\n",
       "        0.00073571, 0.00071449, 0.00070229, 0.00071564, 0.00069013,\n",
       "        0.00068402, 0.0008348 , 0.00086579, 0.00078945, 0.0007586 ,\n",
       "        0.00075526, 0.00079341, 0.0007967 , 0.00075941, 0.00077863,\n",
       "        0.0007627 , 0.00077581, 0.00114198, 0.00083623, 0.00082641,\n",
       "        0.00085964, 0.00088696, 0.00086617, 0.00082865, 0.0008359 ,\n",
       "        0.00084453, 0.00095582, 0.00089674, 0.00089478, 0.00087748,\n",
       "        0.00090837, 0.00089521, 0.0008698 , 0.00088305, 0.00087485,\n",
       "        0.00244317, 0.00099311, 0.0009635 , 0.00099597, 0.00114751,\n",
       "        0.00113263, 0.00106044, 0.00104923, 0.00127478, 0.0012845 ,\n",
       "        0.0011693 , 0.00119023, 0.00118089, 0.00123639, 0.00124702,\n",
       "        0.00142064, 0.00136795, 0.00127606, 0.00158014, 0.00106664,\n",
       "        0.00103641, 0.00098066, 0.00095778, 0.00096068, 0.00094299,\n",
       "        0.00100689, 0.00092354, 0.00106573, 0.00102572, 0.00105176,\n",
       "        0.00105653, 0.00097861, 0.00109367, 0.00096087, 0.00095215,\n",
       "        0.00095091]),\n",
       " 'std_fit_time': array([7.69919119e-05, 1.00523350e-03, 3.86371931e-04, 5.93871505e-04,\n",
       "        5.74296069e-05, 2.81120923e-04, 1.85483096e-04, 5.59175300e-04,\n",
       "        2.04171715e-04, 8.94377973e-05, 3.76892645e-05, 6.22456805e-05,\n",
       "        3.91147751e-05, 4.71487072e-05, 1.12725353e-05, 5.16879163e-06,\n",
       "        1.97705944e-04, 2.17648172e-04, 5.09612449e-05, 5.23305699e-06,\n",
       "        3.77695968e-06, 6.05553904e-05, 3.67544028e-05, 8.88428375e-06,\n",
       "        2.50361759e-05, 1.77502592e-05, 4.24607358e-05, 2.38361275e-04,\n",
       "        6.67503898e-06, 6.65935144e-06, 4.86840230e-05, 8.11547426e-05,\n",
       "        6.48729900e-05, 1.13729411e-05, 3.55123653e-05, 3.05984588e-05,\n",
       "        1.04999499e-04, 8.45549398e-06, 2.41276775e-05, 5.87613532e-06,\n",
       "        3.92437271e-05, 2.26175682e-05, 6.75595971e-06, 2.27213782e-05,\n",
       "        1.69345009e-05, 2.99878163e-03, 7.88346958e-05, 4.24849331e-05,\n",
       "        1.15865798e-04, 2.33591228e-04, 1.82230206e-04, 2.15056751e-04,\n",
       "        8.92333443e-05, 2.02224632e-04, 2.61752095e-04, 1.94743740e-04,\n",
       "        1.98994001e-04, 1.81318419e-04, 2.37411920e-04, 1.93283964e-04,\n",
       "        4.78219413e-05, 5.25068084e-05, 1.15414531e-04, 9.70090715e-05,\n",
       "        5.52025051e-05, 9.59790407e-05, 1.14930615e-05, 1.04179917e-05,\n",
       "        1.64059703e-05, 2.21004635e-05, 5.96098707e-05, 1.95715951e-05,\n",
       "        1.22195046e-05, 1.33492264e-05, 8.34016134e-05, 5.94133359e-05,\n",
       "        1.52979289e-05, 1.45716271e-04, 2.24870054e-05, 4.32553597e-05,\n",
       "        2.90880828e-05]),\n",
       " 'mean_score_time': array([0.00383716, 0.00172954, 0.00181694, 0.00230951, 0.00098739,\n",
       "        0.00213237, 0.00131383, 0.00115738, 0.00114055, 0.00093756,\n",
       "        0.00091648, 0.00092111, 0.00090051, 0.00091166, 0.00090766,\n",
       "        0.00090671, 0.00116191, 0.00103512, 0.00092936, 0.0009016 ,\n",
       "        0.0009274 , 0.00091076, 0.00091596, 0.0009058 , 0.00091801,\n",
       "        0.00090017, 0.00097437, 0.00122795, 0.00090981, 0.00096898,\n",
       "        0.00090442, 0.0009161 , 0.00105462, 0.00093451, 0.00090337,\n",
       "        0.00094233, 0.00092316, 0.00092831, 0.00090818, 0.00091496,\n",
       "        0.00092368, 0.00096931, 0.00090342, 0.00092072, 0.00092282,\n",
       "        0.00094476, 0.00092993, 0.0010088 , 0.00099254, 0.0012104 ,\n",
       "        0.00116124, 0.00097904, 0.0013    , 0.0015492 , 0.00108929,\n",
       "        0.00107989, 0.00121999, 0.00107799, 0.00123191, 0.00294881,\n",
       "        0.00155177, 0.00136914, 0.00140228, 0.00153923, 0.00094981,\n",
       "        0.00242262, 0.00092134, 0.00092897, 0.00091672, 0.00092373,\n",
       "        0.00094881, 0.0009088 , 0.00092025, 0.00091381, 0.00237846,\n",
       "        0.00092759, 0.00093503, 0.00095553, 0.00093236, 0.00090837,\n",
       "        0.00091667]),\n",
       " 'std_score_time': array([3.20475369e-03, 2.11480661e-04, 6.85687844e-04, 8.84170733e-04,\n",
       "        4.92350472e-05, 1.94123268e-03, 3.86639628e-04, 3.65772102e-04,\n",
       "        3.94820775e-04, 2.74633367e-05, 2.05444336e-05, 2.59977286e-05,\n",
       "        3.27597886e-06, 2.28580634e-05, 1.96512455e-05, 1.41082570e-05,\n",
       "        3.27347601e-04, 2.43425934e-04, 4.41704120e-05, 4.96139840e-06,\n",
       "        5.93303856e-05, 1.05347563e-05, 1.69699103e-05, 5.42296148e-06,\n",
       "        1.45997851e-05, 3.23617544e-06, 1.36510109e-04, 3.57428482e-04,\n",
       "        1.05649296e-05, 1.23032618e-04, 5.80998243e-06, 2.10714551e-05,\n",
       "        2.12425126e-04, 6.11041469e-05, 8.83758211e-06, 4.62926618e-05,\n",
       "        4.03622305e-05, 4.71487072e-05, 7.77902500e-06, 3.10949748e-05,\n",
       "        2.90492860e-05, 1.09449305e-04, 2.43793927e-06, 2.68071557e-05,\n",
       "        2.43689448e-05, 5.37889646e-05, 5.37166318e-05, 1.94755637e-04,\n",
       "        1.21033257e-04, 3.72880298e-04, 2.03190916e-04, 9.13388516e-05,\n",
       "        2.96348850e-04, 9.76066531e-04, 8.22769217e-05, 1.62093959e-04,\n",
       "        2.58868960e-04, 2.49098956e-04, 2.44822101e-04, 3.44944426e-03,\n",
       "        3.16256924e-04, 2.41620150e-04, 2.35122789e-05, 1.08874882e-04,\n",
       "        4.37728720e-05, 3.01171809e-03, 3.23682879e-05, 4.59871308e-05,\n",
       "        1.83795830e-05, 3.30054681e-05, 4.88290563e-05, 4.89635378e-06,\n",
       "        1.13156180e-05, 7.67011504e-06, 2.91568800e-03, 1.21799930e-05,\n",
       "        4.98169103e-05, 5.19269754e-05, 3.90362209e-05, 6.06727270e-06,\n",
       "        1.04201739e-05]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 1, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 1},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9}],\n",
       " 'split0_test_score': array([0.75555556, 0.75555556, 0.75555556, 0.75555556, 0.75555556,\n",
       "        0.75555556, 0.75555556, 0.75555556, 0.75555556, 0.76712329,\n",
       "        0.76712329, 0.76712329, 0.76712329, 0.76712329, 0.76712329,\n",
       "        0.76712329, 0.76712329, 0.76712329, 0.76712329, 0.76712329,\n",
       "        0.76712329, 0.76712329, 0.76712329, 0.76712329, 0.76712329,\n",
       "        0.76712329, 0.76712329, 0.84      , 0.82352941, 0.84      ,\n",
       "        0.84      , 0.84      , 0.84      , 0.84      , 0.84      ,\n",
       "        0.8030303 , 0.80327869, 0.79032258, 0.79661017, 0.77419355,\n",
       "        0.78125   , 0.78125   , 0.78125   , 0.78125   , 0.81666667,\n",
       "        0.7027027 , 0.67105263, 0.69736842, 0.70833333, 0.7027027 ,\n",
       "        0.69863014, 0.79365079, 0.79365079, 0.80952381, 0.78125   ,\n",
       "        0.765625  , 0.79032258, 0.81355932, 0.79032258, 0.8       ,\n",
       "        0.73239437, 0.72463768, 0.72857143, 0.73611111, 0.75362319,\n",
       "        0.75714286, 0.83606557, 0.77941176, 0.78787879, 0.7761194 ,\n",
       "        0.76923077, 0.77272727, 0.68918919, 0.69565217, 0.71014493,\n",
       "        0.75409836, 0.68918919, 0.72463768, 0.7761194 , 0.76923077,\n",
       "        0.77272727]),\n",
       " 'split1_test_score': array([0.70689655, 0.70689655, 0.70689655, 0.70689655, 0.70689655,\n",
       "        0.70689655, 0.70689655, 0.70689655, 0.70689655, 0.6835443 ,\n",
       "        0.6835443 , 0.6835443 , 0.6835443 , 0.6835443 , 0.6835443 ,\n",
       "        0.6835443 , 0.6835443 , 0.6835443 , 0.8       , 0.8       ,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "        0.8       , 0.8       , 0.84444444, 0.84782609, 0.84782609,\n",
       "        0.84782609, 0.84782609, 0.84782609, 0.84782609, 0.84782609,\n",
       "        0.84782609, 0.75409836, 0.75806452, 0.75806452, 0.75806452,\n",
       "        0.75384615, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.72580645, 0.73770492, 0.75      , 0.74576271, 0.78947368,\n",
       "        0.80701754, 0.81355932, 0.81034483, 0.81355932, 0.73770492,\n",
       "        0.77586207, 0.78571429, 0.72131148, 0.77192982, 0.80701754,\n",
       "        0.78947368, 0.77586207, 0.77966102, 0.71428571, 0.80357143,\n",
       "        0.76363636, 0.71186441, 0.76785714, 0.79310345, 0.78947368,\n",
       "        0.77586207, 0.77966102, 0.70967742, 0.78181818, 0.77777778,\n",
       "        0.71186441, 0.76785714, 0.79310345, 0.78947368, 0.77586207,\n",
       "        0.77966102]),\n",
       " 'split2_test_score': array([0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
       "        0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.734375  ,\n",
       "        0.734375  , 0.734375  , 0.734375  , 0.734375  , 0.734375  ,\n",
       "        0.734375  , 0.734375  , 0.734375  , 0.76666667, 0.76666667,\n",
       "        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,\n",
       "        0.76666667, 0.76666667, 0.75409836, 0.76666667, 0.76666667,\n",
       "        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,\n",
       "        0.76666667, 0.74137931, 0.75438596, 0.75438596, 0.75438596,\n",
       "        0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.78      ,\n",
       "        0.703125  , 0.73770492, 0.73770492, 0.74603175, 0.76363636,\n",
       "        0.76363636, 0.75      , 0.75      , 0.75925926, 0.69230769,\n",
       "        0.73770492, 0.75384615, 0.76119403, 0.78333333, 0.78333333,\n",
       "        0.7704918 , 0.7704918 , 0.77966102, 0.70149254, 0.72580645,\n",
       "        0.75409836, 0.7704918 , 0.76666667, 0.77419355, 0.76190476,\n",
       "        0.76190476, 0.7704918 , 0.68656716, 0.76666667, 0.72580645,\n",
       "        0.77966102, 0.76666667, 0.77419355, 0.76190476, 0.76190476,\n",
       "        0.7704918 ]),\n",
       " 'split3_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.70149254, 0.70149254,\n",
       "        0.70149254, 0.70149254, 0.70149254, 0.70149254, 0.70149254,\n",
       "        0.70149254, 0.70149254, 0.73015873, 0.73015873, 0.71875   ,\n",
       "        0.71875   , 0.71875   , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.72580645, 0.72580645, 0.71428571, 0.71428571,\n",
       "        0.73770492, 0.73333333, 0.70833333, 0.70833333, 0.70833333,\n",
       "        0.69863014, 0.69863014, 0.68918919, 0.68918919, 0.69333333,\n",
       "        0.70833333, 0.71232877, 0.71052632, 0.71052632, 0.68918919,\n",
       "        0.68918919, 0.70833333, 0.68918919, 0.69333333, 0.71428571,\n",
       "        0.72727273, 0.74626866, 0.73529412, 0.68918919, 0.72857143,\n",
       "        0.68      , 0.734375  , 0.71641791, 0.74193548, 0.70833333,\n",
       "        0.7260274 , 0.71621622, 0.69736842, 0.71830986, 0.69230769,\n",
       "        0.69863014, 0.68918919, 0.72058824, 0.72857143, 0.73913043,\n",
       "        0.73239437]),\n",
       " 'split4_test_score': array([0.65079365, 0.65079365, 0.65079365, 0.65079365, 0.65079365,\n",
       "        0.65079365, 0.65079365, 0.65079365, 0.65079365, 0.73584906,\n",
       "        0.73584906, 0.73584906, 0.73584906, 0.73584906, 0.73584906,\n",
       "        0.73584906, 0.73584906, 0.73584906, 0.73913043, 0.73913043,\n",
       "        0.73913043, 0.73913043, 0.73913043, 0.73913043, 0.73913043,\n",
       "        0.73913043, 0.73913043, 0.74137931, 0.74137931, 0.74137931,\n",
       "        0.74137931, 0.74137931, 0.74137931, 0.74137931, 0.74137931,\n",
       "        0.74137931, 0.71186441, 0.71186441, 0.734375  , 0.734375  ,\n",
       "        0.734375  , 0.734375  , 0.73846154, 0.78846154, 0.78846154,\n",
       "        0.76      , 0.74074074, 0.73469388, 0.73469388, 0.73469388,\n",
       "        0.73469388, 0.74      , 0.7254902 , 0.74074074, 0.71186441,\n",
       "        0.7       , 0.75438596, 0.75471698, 0.76923077, 0.74509804,\n",
       "        0.75      , 0.75471698, 0.76785714, 0.72727273, 0.70689655,\n",
       "        0.74074074, 0.70909091, 0.74509804, 0.74074074, 0.75      ,\n",
       "        0.75471698, 0.76785714, 0.72881356, 0.71186441, 0.75471698,\n",
       "        0.7037037 , 0.74509804, 0.73469388, 0.75      , 0.75471698,\n",
       "        0.76785714]),\n",
       " 'mean_test_score': array([0.71153804, 0.71153804, 0.71153804, 0.71153804, 0.71153804,\n",
       "        0.71153804, 0.71153804, 0.71153804, 0.71153804, 0.734998  ,\n",
       "        0.734998  , 0.734998  , 0.734998  , 0.734998  , 0.734998  ,\n",
       "        0.734998  , 0.734998  , 0.734998  , 0.75488259, 0.75488259,\n",
       "        0.75488259, 0.75488259, 0.75488259, 0.75488259, 0.75488259,\n",
       "        0.75488259, 0.75488259, 0.78201617, 0.78191204, 0.78292441,\n",
       "        0.78292441, 0.78292441, 0.78203156, 0.78203156, 0.78203156,\n",
       "        0.77463762, 0.74728544, 0.74808878, 0.75154427, 0.74706095,\n",
       "        0.75528137, 0.75773618, 0.75355349, 0.76355349, 0.77279067,\n",
       "        0.71805286, 0.71716667, 0.72179128, 0.72480217, 0.73676799,\n",
       "        0.74246225, 0.76190778, 0.75800243, 0.76672189, 0.72246324,\n",
       "        0.73367624, 0.75852046, 0.7479942 , 0.76162997, 0.76994693,\n",
       "        0.75392652, 0.75439544, 0.75820894, 0.71367026, 0.74369381,\n",
       "        0.73912366, 0.75237754, 0.7550903 , 0.7675704 , 0.75716624,\n",
       "        0.7575484 , 0.76139069, 0.70232315, 0.73486226, 0.73215077,\n",
       "        0.72959153, 0.73160005, 0.74944336, 0.76121386, 0.760169  ,\n",
       "        0.76462632]),\n",
       " 'std_test_score': array([0.04909197, 0.04909197, 0.04909197, 0.04909197, 0.04909197,\n",
       "        0.04909197, 0.04909197, 0.04909197, 0.04909197, 0.02844452,\n",
       "        0.02844452, 0.02844452, 0.02844452, 0.02844452, 0.02844452,\n",
       "        0.02844452, 0.02844452, 0.02844452, 0.03293299, 0.03293299,\n",
       "        0.03293299, 0.03293299, 0.03293299, 0.03293299, 0.03293299,\n",
       "        0.03293299, 0.03293299, 0.04975815, 0.04610943, 0.05211241,\n",
       "        0.05211241, 0.05211241, 0.05323053, 0.05323053, 0.05323053,\n",
       "        0.04685019, 0.03140872, 0.02731875, 0.02743905, 0.02071744,\n",
       "        0.01798346, 0.0199448 , 0.0267298 , 0.02850689, 0.03572866,\n",
       "        0.02304514, 0.027819  , 0.02397843, 0.02248285, 0.036197  ,\n",
       "        0.0394008 , 0.03675684, 0.03843331, 0.03978543, 0.03410879,\n",
       "        0.03443772, 0.02935497, 0.04168504, 0.03499312, 0.03513474,\n",
       "        0.02335588, 0.01828432, 0.0219861 , 0.01695062, 0.03342635,\n",
       "        0.03048943, 0.04726722, 0.02228873, 0.02229445, 0.02779012,\n",
       "        0.01727679, 0.02292466, 0.01549922, 0.03333675, 0.03066932,\n",
       "        0.03178231, 0.03556347, 0.0289284 , 0.02103592, 0.0126787 ,\n",
       "        0.01658559]),\n",
       " 'rank_test_score': array([72, 72, 72, 72, 72, 72, 72, 72, 72, 52, 52, 52, 52, 52, 52, 52, 52,\n",
       "        52, 29, 29, 29, 29, 29, 29, 29, 29, 29,  7,  8,  1,  1,  1,  4,  4,\n",
       "         4,  9, 46, 44, 42, 47, 27, 24, 40, 15, 10, 69, 70, 68, 66, 51, 49,\n",
       "        16, 23, 13, 67, 62, 21, 45, 17, 11, 39, 38, 22, 71, 48, 50, 41, 28,\n",
       "        12, 26, 25, 18, 81, 61, 63, 65, 64, 43, 19, 20, 14], dtype=int32)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) ->  GridSearchCV:\n",
    "    params = { 'max_depth': np.arange(1, 10), 'min_samples_leaf': np.arange(1, 10) }\n",
    "    gs = GridSearchCV(\n",
    "        estimator = DTC(),\n",
    "        param_grid = params,\n",
    "        cv = 5,\n",
    "        scoring = 'precision'\n",
    "    )\n",
    "    return gs.fit(X, y)\n",
    "\n",
    "X = pd.read_csv('sonar_train.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('sonar_train.csv')['y']\n",
    "fitted = fit_gs(X, Y)\n",
    "fitted.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). \n",
    "\n",
    "Обучите $2$ `DTC`. Один с количеством итераций - $10$, другой с количеством итераций $50$. Верните обе обученные модели в соответствующем порядке.\n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные по [ссылке](https://yadi.sk/d/6pUM_Ko-RtqiZg)\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "1       0.001987      0.000261         0.007144        0.007229   \n",
      "4       0.001024      0.000087         0.000926        0.000025   \n",
      "8       0.001061      0.000189         0.002466        0.003015   \n",
      "\n",
      "  param_min_samples_leaf param_max_depth  \\\n",
      "1                      7               4   \n",
      "4                      6               8   \n",
      "8                      8               5   \n",
      "\n",
      "                                    params  split0_test_score  \\\n",
      "1  {'min_samples_leaf': 7, 'max_depth': 4}           0.840000   \n",
      "4  {'min_samples_leaf': 6, 'max_depth': 8}           0.787879   \n",
      "8  {'min_samples_leaf': 8, 'max_depth': 5}           0.781250   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "1           0.847826           0.766667           0.714286           0.741379   \n",
      "4           0.793103           0.774194           0.741935           0.740741   \n",
      "8           0.770492           0.769231           0.708333           0.788462   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "1         0.782032        0.053231                1  \n",
      "4         0.767570        0.022294                2  \n",
      "8         0.763553        0.028507                3  \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "29       0.000927      0.000090         0.000949        0.000044   \n",
      "17       0.000850      0.000039         0.000963        0.000057   \n",
      "13       0.000895      0.000141         0.000917        0.000018   \n",
      "\n",
      "   param_min_samples_leaf param_max_depth  \\\n",
      "29                      8               4   \n",
      "17                      7               4   \n",
      "13                      6               4   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "29  {'min_samples_leaf': 8, 'max_depth': 4}               0.84   \n",
      "17  {'min_samples_leaf': 7, 'max_depth': 4}               0.84   \n",
      "13  {'min_samples_leaf': 6, 'max_depth': 4}               0.84   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "29           0.847826           0.766667           0.714286   \n",
      "17           0.847826           0.766667           0.714286   \n",
      "13           0.847826           0.766667           0.714286   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "29           0.741379         0.782032        0.053231                1  \n",
      "17           0.741379         0.782032        0.053231                1  \n",
      "13           0.741379         0.782032        0.053231                1  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) -> (RandomizedSearchCV, RandomizedSearchCV):\n",
    "    params = { 'max_depth': np.arange(1, 10), 'min_samples_leaf': np.arange(1, 10) }\n",
    "    rs10 = RandomizedSearchCV(\n",
    "        estimator = DTC(),\n",
    "        param_distributions = params,\n",
    "        cv = 5,\n",
    "        scoring = 'precision'\n",
    "    )\n",
    "    rs50 = RandomizedSearchCV(\n",
    "        estimator = DTC(),\n",
    "        param_distributions = params,\n",
    "        cv = 5,\n",
    "        scoring = 'precision',\n",
    "        n_iter = 50\n",
    "    )\n",
    "    return rs10.fit(X, y), rs50.fit(X, y)\n",
    "\n",
    "X = pd.read_csv('sonar_train.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('sonar_train.csv')['y']\n",
    "rs10, rs50 = fit_gs(X, Y)\n",
    "print(pd.DataFrame(rs10.cv_results_).sort_values(by='rank_test_score').head(3))\n",
    "print(pd.DataFrame(rs50.cv_results_).sort_values(by='rank_test_score').head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Моя Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо реальзовать собственную функцию кросс-валидации. \n",
    "\n",
    "Напоминание, кросс-валидация: \n",
    "1. Разбивает, предварительно перемешав, данные на $k$ (заданное) `фолдов` данных (если нацело данные не делятся - хвост отбрасываем).\n",
    "2. Берет один из фолдов за тестовую выборку, а все остальное за тренировачную.\n",
    "3. Обучает эстиматор на тренировачных данныx \n",
    "4. Cчитает `score` обученной модели.\n",
    "5. 2-4 шаги повторяются для всех $k$ фолдов \n",
    "\n",
    "Она должна принимать на вход: \n",
    "* `estimator`, который мы хотим обучить на разных фолдах данных\n",
    "* $X, y$ - данные \n",
    "* `cv` ($k$) - объект разбиения `KFold` или количество фолдов, на которые мы бьем данные (по умолчанию 3)\n",
    "* `scoring` - функция метрики, по которой оцениваем полученные результаты (замечание: в реальной `cross_val_score` здесь будет стоять объект `scorer`, у нас же будет стоять функция, например `metrics.accuracy_score`)\n",
    "\n",
    "На выходе мы получаем массив длины $k$ из score значений.\n",
    "\n",
    "Подсказка: используйте `model_selection.KFold` для разбиения выборки.\n",
    "\n",
    "Подсказка: не нужно shuffl-ить данные при создании `KFold` из `cv`! \n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "estimator = LinearRegression()\n",
    "X = np.array([[1],[2],[3],[4],[5]])\n",
    "y = np.array([1, 2, 4, 4, 6])\n",
    "cv = 2\n",
    "scoring = sklearn.metrics.r2_score\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([-2.64285714 -0.23611111])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [3 4] TEST: [0 1 2]\n",
      "TRAIN: [0 1 2] TEST: [3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-2.6428571428571366, -0.2361111111111105]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def my_cross_val_score(estimator, X, y, cv=3, scoring=accuracy_score):\n",
    "    if type(cv) == int:\n",
    "        cv = KFold(n_splits=cv)\n",
    "    scorings = []\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_pred = estimator.predict(X_test)\n",
    "        scorings.append(scoring(y_test, y_pred))\n",
    "    return scorings\n",
    "    \n",
    "estimator = LinearRegression()\n",
    "X = np.array([[1],[2],[3],[4],[5]])\n",
    "y = np.array([1, 2, 4, 4, 6])\n",
    "cv = 2\n",
    "scoring = r2_score\n",
    "my_cross_val_score(estimator, X, y, cv, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
