{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Основы метрик классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход подаются 2 массива $y_{real}$ - реальные значения бинарных классов и $y_{pred}$ - предсказанные значения бинарных классов. Вам необходимо посчитать, не используя стандартные функции, метрики: \n",
    "* $accuracy$\n",
    "* $precision$\n",
    "* $recall$\n",
    "* $F_1$\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n",
    "y_pred = np.array([0, 1, 1, 0, 1, 1, 0, 0])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.625, 0.75, 0.6, 0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_metrics(y_real, y_pred) -> (float, float, float, float):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Основы метрик регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решаем задачу регрессии. На вход подаются 2 массива $y_{real}$ - реальные значения функции и $y_{pred}$ - предсказанные значения функции. Вам необходимо посчитать, не используя стандартные функции, метрики: \n",
    "* $R^2score$\n",
    "* $MAE$ - `mean_absolute_error`\n",
    "* $MSE$ - `mean_squared_error`\n",
    "* $MSLE$ - `mean_squared_log_error`\n",
    "\n",
    "Возвращать числа нужно именно в данном порядке.\n",
    "\n",
    "Формулы для метрик - ищите в интернете, это часть задания. Можете сверяться с реальными метриками в `sklearn.metrics`.\n",
    "\n",
    "Все числа в тестах больше 0, поэтому $MSLE$ будет считаться корректно\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([1, 2, 3, 4, 6])\n",
    "y_pred = np.array([1, 3, 2, 4, 5])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "0.797297, 0.6, 0.6, 0.037856\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_metrics(y_real, y_pred) -> (float, float, float, float):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) LogLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте свой LogLoss метрику.\n",
    "\n",
    "В результат $y_{real}$ - передаются значения бинарных классов. В $y_{prob}$ - передаются вероятности $P(y_{pred}=1)$. Чтобы обработать краевые случаи в $y_{prob}$: \n",
    "* $0$ нужно заменить на `eps`\n",
    "* $1$ нужно заменить на ($1$ - `eps`).\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([  1, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6,   0])\n",
    "```\n",
    "#### Output:\n",
    "``` python\n",
    "    0.325921\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_real, y_pred, eps=1e-15):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Нахождение Roc-curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход даны $y_{real}$ и массив вероятностей $P(y_{pred}=1)$ необходимо реализовать функцию `roc-curve`, которая вернет 2 массива различных значений fpr и tpr, для дальнейшего построения Roc кривой.\n",
    "\n",
    "Можно считать, что все вероятности ограничены $decimal=2$ (у каждого числа не более 2-х знаков после запятой)\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.6, 0.4, 0.6, 0.6, 0.4])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0.,  0.4, 0.6, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "### Sample 2\n",
    "#### Input:\n",
    "```python\n",
    "y_real = np.array([  1,   1,   0,   0,   1,   0,   1,   0])\n",
    "y_prob = np.array([0.8, 0.8, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6])\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([0.,  0., 0.25, 0.5, 1. ]), #fpr\n",
    "array([0., 0.5, 0.75,  1., 1. ])  #tpr\n",
    "\n",
    "или \n",
    "\n",
    "array([0.,  0., 0.5, 1. ]), #fpr\n",
    "array([0., 0.5,  1., 1. ])  #tpr\n",
    "```\n",
    "\n",
    "Обратите внимание на 2 пример: roc кривая, которая задается ими - одинаковая. Точка, которая уходит, находится на прямой между двумя соседними, в целом такие точки можно убирать, но будут приниматься оба варианта. Функция `sklearn.metrics.roc_curve` возвращает второй вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(y_real, y_prob) -> (np.array, np.array):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход падаются [данные](https://yadi.sk/d/6pUM_Ko-RtqiZg) и $k$ - число фолдов в кросс-валидации. Верните значения кросс-валидации по $k$ фолдам алгоритма `LogisticRegression` с метрикой `neg_log_loss`. \n",
    "\n",
    "В итоге должны получиться значения не ниже $-1$.\n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "X = pd.read_csv('resources/train.csv').drop(columns=['y']).values\n",
    "Y = pd.read_csv('resources/train.csv')['y']\n",
    "k = 3\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([-0.45456358, -0.41684932, -0.49260998])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(X, y, k):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) и верните обученный grid_search. \n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные по [ссылке](https://yadi.sk/d/6pUM_Ko-RtqiZg)\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) ->  GridSearchCV:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) найдите лучшие коэффициенты гиперпараметров `max_depth` и `min_samples_leaf` для классификатора [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). \n",
    "\n",
    "Обучите $2$ `DTC`. Один с количеством итераций - $10$, другой с количеством итераций $50$. Верните обе обученные модели в соответствующем порядке.\n",
    "\n",
    "* Пределы `max_depth` $(1, 10)$ \n",
    "* Пределы `min_samples_leaf` $(1, 10)$  \n",
    "* Входные данные по [ссылке](https://yadi.sk/d/6pUM_Ko-RtqiZg)\n",
    "* scoring - `precision`\n",
    "* cv - $5$\n",
    "* Другие параметры в `DecisionTreeClassifier` не указывать.\n",
    "\n",
    "Не нужно Shuffl-ить данные, это может повлиять на ответ и в итоге задача не зачтется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "\n",
    "def fit_gs(X: np.ndarray, y: np.ndarray) -> (RandomizedSearchCV, RandomizedSearchCV):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Моя Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо реальзовать собственную функцию кросс-валидации. \n",
    "\n",
    "Напоминание, кросс-валидация: \n",
    "1. Разбивает, предварительно перемешав, данные на $k$ (заданное) `фолдов` данных (если нацело данные не делятся - хвост отбрасываем).\n",
    "2. Берет один из фолдов за тестовую выборку, а все остальное за тренировачную.\n",
    "3. Обучает эстиматор на тренировачных данныx \n",
    "4. Cчитает `score` обученной модели.\n",
    "5. 2-4 шаги повторяются для всех $k$ фолдов \n",
    "\n",
    "Она должна принимать на вход: \n",
    "* `estimator`, который мы хотим обучить на разных фолдах данных\n",
    "* $X, y$ - данные \n",
    "* `cv` ($k$) - объект разбиения `KFold` или количество фолдов, на которые мы бьем данные (по умолчанию 3)\n",
    "* `scoring` - функция метрики, по которой оцениваем полученные результаты (замечание: в реальной `cross_val_score` здесь будет стоять объект `scorer`, у нас же будет стоять функция, например `metrics.accuracy_score`)\n",
    "\n",
    "На выходе мы получаем массив длины $k$ из score значений.\n",
    "\n",
    "Подсказка: используйте `model_selection.KFold` для разбиения выборки.\n",
    "\n",
    "Подсказка: не нужно shuffl-ить данные при создании `KFold` из `cv`! \n",
    "\n",
    "### Sample\n",
    "#### Input:\n",
    "```python\n",
    "estimator = LinearRegression()\n",
    "X = np.array([[1],[2],[3],[4],[5]])\n",
    "y = np.array([1, 2, 4, 4, 6])\n",
    "cv = 2\n",
    "scoring = sklearn.metrics.r2_score\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "array([-2.64285714 -0.23611111])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "def my_cross_val_score(estimator, X, y, cv=3, scoring=accuracy_score, random_state=42):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
