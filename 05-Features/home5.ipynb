{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"resources/train.csv\")\n",
    "test = pd.read_csv(\"resources/test.csv\")\n",
    "sample_submission = pd.read_csv(\"resources/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Удаление Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия задач в данном модуле объединена в одну [большую задачу по предсказанию данных](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). В ходе выполнения модуля мы будем разбирать определенные техники, которые нужны для ее решения. Настоятельно рекомендуем выполнить все шаги по порядку, тогда в конце вы получите решение большой реальной задачи по МЛ.\n",
    "\n",
    "Нам даны [данные](https://yadi.sk/d/tcElz6cqSNpPqA) о домах выставленных на продажу. Нам необходимо решить задачу регрессии и предсказать цену продажи дома для $X_{test}$ по данным $X_{train}$ и $y_{train}$. В нашем случае  $y_{train}$ - это столбик `SalePrice`, $X_{train}$ - все остальные столбики.\n",
    "\n",
    "На вход подается 2 считанных датафрейма **df_train**, **df_test** из файлов без изменений. \n",
    "\n",
    "Начальная подготовка:\n",
    " * Разделить **df_train** на **X_train**(`pd.Dataframe`) и **y_train**(`pd.Series`).\n",
    " * Сконкатенировать **X_train** и **df_test** в **df** по вертикали (можно ориентироваться по столбику `Id` они как раз идут по-порядку). Не забудьте обновить индекс!\n",
    "\n",
    "Задачи:\n",
    " * Заменить в **df** все Nan-ы в категориальных признаках (`object`) на строку `missing`\n",
    " * Заменить в **df** все Nan-ы в числовых признаках на 0.\n",
    "\n",
    "Вернуть из функции измененный **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def del_nan(df_train: pd.DataFrame, df_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    train = df_train.copy()\n",
    "    y_train = train['SalePrice']\n",
    "    X_train = train.drop(['SalePrice'], axis='columns')\n",
    "    df = pd.concat([X_train, df_test], axis=0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.loc[:, df.dtypes == np.object] = df.loc[:, df.dtypes == np.object].fillna('missing')\n",
    "    df.loc[:, df.dtypes == np.number] = df.loc[:, df.dtypes == np.number].fillna(0)\n",
    "    return df\n",
    "\n",
    "df_without_nan = del_nan(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Порядковые категории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам на вход приходит **df** из предыдущей задачи.\n",
    "\n",
    "Если внимательно изучить файл `data_description` можно понять, что многие категориальные признаки - порядковые (упорядоченное множество). Значит их можно перевести в осмысленные числа. Значит тут можно воспользоваться `LabelEncoding`.\n",
    "\n",
    "Ваша задача: заменить в **df** категориальные признаки на числовые, для порядковых признаков.\n",
    "\n",
    "На выходе возвращаем измененный **df**.\n",
    "\n",
    "Чтобы слегка упростить вам жизнь, вот вам готовые словари для перевода. Однако к каким столбцам их применять - вы должны выяснить сами, изучив файл `data_description`. Каждый маппинг используется хотя бы 1 раз, а некоторые и не по одному разу.\n",
    "\n",
    "```python\n",
    "{'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'missing':0}\n",
    "{'Gd':4, 'Av': 3, 'Mn': 2, 'No': 1, 'missing': 0}\n",
    "{'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'missing': 0}\n",
    "{'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, 'missing': 0}\n",
    "{'Fin': 3, 'RFn': 2, 'Unf': 1, 'missing': 0}\n",
    "{'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'missing': 0}\n",
    "{'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1, 'missing': 0}\n",
    "{'Lvl': 4, 'Bnk': 3, 'HLS':2,'Low':1, 'missing': 0}\n",
    "{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'missing':0}\n",
    "{'Gtl':3, 'Mod':2, 'Sev':1, 'missing':0}\n",
    "{'SBrkr':5, 'FuseA':4, 'FuseF':3, 'FuseP':2, 'Mix':1, 'missing':0}\n",
    "{'Y':3, 'P':2, 'N':1, 'missing':0}\n",
    "{'Y':1, 'N':0, 'missing':0} #тут нет ошибки, все так и задумано:)\n",
    "```\n",
    "\n",
    "Подсказка: после перевода у вас должно остаться 21 категориальных признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'missing':0}\n",
    "exposure = {'Gd':4, 'Av': 3, 'Mn': 2, 'No': 1, 'missing': 0}\n",
    "bsmt_rating = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'missing': 0}\n",
    "functional = {'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1, 'missing': 0}\n",
    "finish = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'missing': 0}\n",
    "fence = {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'missing': 0}\n",
    "shape = {'Reg': 4, 'IR1': 3, 'IR2': 2, 'IR3': 1, 'missing': 0}\n",
    "flatness = {'Lvl': 4, 'Bnk': 3, 'HLS':2,'Low':1, 'missing': 0}\n",
    "utilities = {'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'missing':0}\n",
    "slope = {'Gtl':3, 'Mod':2, 'Sev':1, 'missing':0}\n",
    "electrical = {'SBrkr':5, 'FuseA':4, 'FuseF':3, 'FuseP':2, 'Mix':1, 'missing':0}\n",
    "yes_what_no = {'Y':3, 'P':2, 'N':1, 'missing':0}\n",
    "yes_no = {'Y':1, 'N':0, 'missing':0} #тут нет ошибки, все так и задумано:)\n",
    "\n",
    "def cat_to_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['ExterQual'] = df['ExterQual'].map(score)\n",
    "    df['ExterCond'] = df['ExterCond'].map(score)\n",
    "    df['BsmtQual'] = df['BsmtQual'].map(score)\n",
    "    df['BsmtCond'] = df['BsmtCond'].map(score)\n",
    "    df['HeatingQC'] = df['HeatingQC'].map(score)\n",
    "    df['KitchenQual'] = df['KitchenQual'].map(score)\n",
    "    df['FireplaceQu'] = df['FireplaceQu'].map(score)\n",
    "    df['GarageQual'] = df['GarageQual'].map(score)\n",
    "    df['GarageCond'] = df['GarageCond'].map(score)\n",
    "    df['PoolQC'] = df['PoolQC'].map(score)\n",
    "    \n",
    "    df['LotShape'] = df['LotShape'].map(shape)\n",
    "    df['LandContour'] = df['LandContour'].map(flatness)\n",
    "    df['Utilities'] = df['Utilities'].map(utilities)\n",
    "    df['LandSlope'] = df['LandSlope'].map(slope)\n",
    "    df['BsmtExposure'] = df['BsmtExposure'].map(exposure)\n",
    "    df['BsmtFinType1'] = df['BsmtFinType1'].map(bsmt_rating)\n",
    "    df['BsmtFinType2'] = df['BsmtFinType2'].map(bsmt_rating)\n",
    "    df['CentralAir'] = df['CentralAir'].map(yes_no)\n",
    "    df['Electrical'] = df['Electrical'].map(electrical)\n",
    "    df['Functional'] = df['Functional'].map(functional)\n",
    "    df['GarageFinish'] = df['GarageFinish'].map(finish)\n",
    "    df['PavedDrive'] = df['PavedDrive'].map(yes_what_no)\n",
    "    df['Fence'] = df['Fence'].map(fence)\n",
    "    return df\n",
    "\n",
    "df_label_encoded = cat_to_num(df_without_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с непорядковыми категориальными признаками.\n",
    "\n",
    "Для начала заметим признак `MSSubClass`, у которого тип `int64`, но если посмотреть в описание `data_description` можно понять, что это - категориальный признак. \n",
    " * Измените тип признака `MSSubClass` с `int64` на `object`\n",
    "\n",
    "Теперь можно сделать `One hot encoding`:\n",
    " * Найдите все колонки с категориальными признаками и составьте из них отдельный **df_oh** `pd.DataFrame` (индекс сохранить прежний)\n",
    " * Применить к полученному фрейму **df_oh** функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) (Реализует `One Hot Encoding`)\n",
    " * Удалить категориальные колонки из **df** и добавить справа к **df** фрейм с `One Hot Encoding`\n",
    " \n",
    "Вернуть из функции **df**\n",
    "\n",
    "Подсказка: итого должно получится 241 колонка из них 183 пришли из `One hot encoding` фрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def one_hot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype('object')\n",
    "    df_oh = df.select_dtypes('object')\n",
    "    df_oh = pd.get_dummies(df_oh)\n",
    "    df = df.loc[:, df.dtypes != np.object]\n",
    "    df = pd.concat([df, df_oh], axis='columns')\n",
    "    return df\n",
    "\n",
    "df_one_hot = one_hot(df_label_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Некоррелирующие признаки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрались с категориальными признаками, теперь разберемся с числовыми.\n",
    "Для числовых признаков можно посчитать корреляцию с правильным ответом. Если признаки слабо коррелируют, то они нам не нужны. Например колонка `Id` явно никак не влияет на стоимость дома.\n",
    "\n",
    "Вам на вход передается изначальный **df_train** и **df** полученный из предыдущей задачи.\n",
    "\n",
    "Ваша задача: \n",
    " * найти корреляцию всех **числовых** признаков **df_train** с признаком `SalePrice` с помощью `pd.corr`\n",
    " * если абсолютное значение корреляции признака с `SalePrice` меньше $0.05$ - удалите этот признак из **df**\n",
    "\n",
    "Верните измененный **df** и столбец корреляции признаков с признаком `SalePrice` упорядоченный по убыванию. Начало столбца корреляции выглядит следующим образом:\n",
    "\n",
    "|               |SalePrice |\n",
    "|---------------|----------|\n",
    "|**SalePrice**  |1.000000  |\n",
    "|**OverallQual**|0.790982  |\n",
    "|**GrLivArea**  |0.708624  |\n",
    "|**GarageCars** |0.640409  |\n",
    "|**GarageArea** |0.623431  |\n",
    "|**TotalBsmtSF**|0.613581  |\n",
    "|**1stFlrSF**   |0.605852  |\n",
    "|**FullBath**   |0.560664  |\n",
    "\n",
    "Всего должно получиться 37 числовых признаков.\n",
    "\n",
    "Подсказка: как мы помним столбец`MSSubClass` - категориальный, уберите его из **df_train** при рассмотрении корреляции.\n",
    "\n",
    "Подсказка: всего придется удалить 8 признаков (включая `Id`). В **df** останется 233 признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def correlation(df: pd.DataFrame, df_train: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    train = df_train.copy()\n",
    "    del train['MSSubClass']\n",
    "    train_number = train.select_dtypes(include='number')\n",
    "    corr_matrix = train_number.corr()\n",
    "    corr_sale_price = corr_matrix.loc[:, 'SalePrice'].sort_values(ascending=False)\n",
    "    bad_corr_columns = corr_sale_price[abs(corr_sale_price) < 0.05].index\n",
    "    df = df.drop(bad_corr_columns, axis='columns')\n",
    "    return df, pd.DataFrame(corr_sale_price, columns=['SalePrice'])\n",
    "    \n",
    "\n",
    "df_with_corr, corr = correlation(df_one_hot, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте нагенерируем несколько фич во входном фрейме **df**:\n",
    " * `TotalArea` = `TotalBsmtSF` + `1stFlrSF` + `2ndFlrSF` + `GrLivArea` + `GarageArea`\n",
    " * `YearAverage` = (`YearRemodAdd` + `YearBuilt`) / 2\n",
    " * `LiveAreaQual` = `OverallQual` * `GrLivArea`\n",
    "\n",
    "На выход отправьте **df** c тремя новымим столбиками. столбцы должны идти в том же порядки что указаны в списке в хвосте **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_en(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['TotalArea'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] + df['GrLivArea'] + df['GarageArea']\n",
    "    df['YearAverage'] = (df['YearRemodAdd'] + df['YearBuilt']) / 2\n",
    "    df['LiveAreaQual'] = df['OverallQual'] * df['GrLivArea']\n",
    "    return df\n",
    "\n",
    "df_featured = feature_en(df_with_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Scaling с выбросами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У стандартного и нормального масштабирования есть одна проблема: она учитывает все признаки, даже те, которые изначально некорректны (шум, выбросы). Чтобы избавитьться от шумов и выбросов и корректно масштабировать выборку необходимо использовать [RobustScaling]((https://scikit-learn.org/0.18/auto_examples/preprocessing/plot_robust_scaling.html).\n",
    "\n",
    "Ваша задача - отмасштабировать полученный фрейм с помощью `RobustScaler`. И вернуть отмасштабированный массив (да, скалирование возвращает массив, а не DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05714286 -0.24511241  0.         ...  0.27028555  0.63414634\n",
      "   0.54896142]\n",
      " [ 0.48571429  0.03592375  0.         ... -0.05654509 -0.02439024\n",
      "  -0.1760633 ]\n",
      " [ 0.14285714  0.43914956 -1.         ...  0.42635001  0.59756098\n",
      "   0.63666337]\n",
      " ...\n",
      " [ 2.77142857  2.57746823  0.         ... -0.05541419  0.02439024\n",
      "  -0.41543027]\n",
      " [-0.02857143  0.24144673  0.         ... -0.84478372  0.36585366\n",
      "  -0.62479393]\n",
      " [ 0.31428571  0.04252199  0.         ...  0.73508623  0.40243902\n",
      "   0.88361358]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def scaling(df: pd.DataFrame) -> np.array:\n",
    "    robust_scaler = RobustScaler()\n",
    "    return robust_scaler.fit_transform(df)\n",
    "\n",
    "X_scaled = scaling(df_featured)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (2) Смешанная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, теперь мы готовы обучать модель! Осталось изучить последний интересный трюк - смешанные модели.\n",
    "\n",
    "Возьмем [2 регрессии](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b):\n",
    " * Ridge\n",
    " * Lasso\n",
    " \n",
    "Найдем оптимальные значения $\\alpha$ для обеих регрессий с помощью GridSearch.\n",
    "\n",
    "Теперь отправим обе модели с наилучшими параметрами в класс указанный снизу. Это класс смешения моделей. В нем параметр $\\beta \\in [0,1]$ - это коэффициент, с которым берется ответ одного классификаторв, а ответ второго - с коэффициентом $(1 - \\beta)$. Такая техника нередко позволяет добиться лучших результатов, чем одна модель.\n",
    "\n",
    "Теперь найдем наилучшее $\\beta$ для смешенной модели также с помощью GridSearch. Осталось получить **y_pred** с помощью наилучшей смешанной модели.\n",
    "\n",
    "На вход вы получаете **X_scaled** из предыдущей задачи и **df_train** начальный. Мы подготовили за вас **X_train**, **y_train** и **X_test**. \n",
    "\n",
    "В задаче необходимо минимизировать метрику `neg_mean_squared_log_error`. Для удобства мы возьмем `np.log1p(y_train)` и будем минимизировать метрику `neg_mean_squared_error`. Эту метрику необходимо минимизировать у всех 3-х GridSearch.\n",
    "\n",
    "На выход отправьте GridSearch объект смешанной модели, а также результат **y_test**. (Не забудьте его проэкспоненциировать).\n",
    "\n",
    "Мы выдаем вам ориентировачные параметры для каждого GridSearch. Вы можете увеличить перебор, чтобы получить лучшую модель.\n",
    "```python\n",
    "params_ridge = {'alpha': np.arange(1, 20)}\n",
    "params_lasso = {'alpha': np.logspace(-4, 3, num=8, base=10)}\n",
    "params_blend = {'beta': np.linspace(0, 1, 11)}\n",
    "```\n",
    "\n",
    "Первые 2 GridSearch **не нужно** писать в функции: они могут работать достаточно долго и превысят лимит работы задачи на сервере. Найдите у себя локально наилучшие параметры и уже с этими параметрами создайте смешанную модель внутри функции. \n",
    "\n",
    "Также не нужно сильно увеличивать перебор для $\\beta$ - того, что есть, более чем достаточно.\n",
    "\n",
    "P.S. Осталось сохранить файл с **y_test** и отправить его в [соревнование](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submit). Улучшайте свои результы пробуя другие модели и другие параметры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "              estimator=BlendRegressor(beta=0.5,\n",
       "                                       clf1=Ridge(alpha=5, copy_X=True,\n",
       "                                                  fit_intercept=True,\n",
       "                                                  max_iter=None, normalize=False,\n",
       "                                                  random_state=None,\n",
       "                                                  solver='auto', tol=0.001),\n",
       "                                       clf2=Lasso(alpha=0.001, copy_X=True,\n",
       "                                                  fit_intercept=True,\n",
       "                                                  max_iter=1000, normalize=False,\n",
       "                                                  positive=False,\n",
       "                                                  precompute=False,\n",
       "                                                  random_state=None,\n",
       "                                                  selection='cyclic', tol=0.0001,\n",
       "                                                  warm_start=False)),\n",
       "              iid='warn', n_jobs=None,\n",
       "              param_grid={'beta': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='neg_mean_squared_error', verbose=0),\n",
       " array([114299.08899306, 152094.58957218, 173164.54938977, ...,\n",
       "        157535.45478296, 111965.1462989 , 224959.5861795 ]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "class BlendRegressor(BaseEstimator): # предок класса классификаторов, чтобы можно было засунуть в GridSearch\n",
    "    def __init__(self, clf1, clf2, beta=0.5):\n",
    "        self.clf1 = clf1 \n",
    "        self.clf2 = clf2\n",
    "        self.beta = beta #параметр смешивания\n",
    "\n",
    "    def fit(self, X, y): #обучаем классификатор\n",
    "        self.X_ = X \n",
    "        self.y_ = y \n",
    "        self.clf1.fit(X, y) \n",
    "        self.clf2.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X): #возвращаем значения \n",
    "        return self.clf1.predict(X) * self.beta + self.clf2.predict(X) * (1 - self.beta)\n",
    "    \n",
    "\n",
    "def get_ridge_gs():\n",
    "    params_ridge = {'alpha': np.arange(1, 20)}\n",
    "    \n",
    "    return GridSearchCV(\n",
    "        estimator = Ridge(),\n",
    "        param_grid = params_ridge,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "def get_lasso_gs():\n",
    "    params_lasso = {'alpha': np.logspace(-4, 3, num=8, base=10)}\n",
    "    \n",
    "    return GridSearchCV(\n",
    "        estimator = Lasso(),\n",
    "        param_grid = params_lasso,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    \n",
    "def learning(X_scaled: np.array, df_train: pd.DataFrame) -> (GridSearchCV, np.array):\n",
    "    X_train = X_scaled[0: len(df_train),]\n",
    "    X_test  = X_scaled[len(df_train): len(X_scaled)]\n",
    "    y_train = np.log1p(df_train['SalePrice'])\n",
    "\n",
    "    params_blend = {'beta': np.linspace(0, 1, 11)}\n",
    "    \n",
    "    blend_gs = GridSearchCV(\n",
    "        estimator = BlendRegressor(Ridge(alpha=5), Lasso(alpha=0.001)),\n",
    "        param_grid = params_blend,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    blend_gs.fit(X_train, y_train)\n",
    "    y_test = blend_gs.predict(X_test)\n",
    "    \n",
    "    return blend_gs, np.exp(y_test) - 1\n",
    "\n",
    "# Calculate best params for Ridge and Lasso models\n",
    "'''\n",
    "X_train = X_scaled[0: len(train),]\n",
    "X_test  = X_scaled[len(train): len(X_scaled)]\n",
    "y_train = np.log1p(train['SalePrice'])\n",
    "\n",
    "ridge_gs = get_ridge_gs()\n",
    "ridge_gs.fit(X_train, y_train)\n",
    "print(ridge_gs.best_params_)\n",
    "\n",
    "lasso_gs = get_lasso_gs()\n",
    "lasso_gs.fit(X_train, y_train)\n",
    "print(lasso_gs.best_params_)\n",
    "'''\n",
    "\n",
    "learning(X_scaled, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
